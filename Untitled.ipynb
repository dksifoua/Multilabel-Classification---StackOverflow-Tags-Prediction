{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "SEED = 78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "Train: (100000, 2)\n",
      "Test: (30000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to draw a stacked dotplot in R?</td>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysql select all records where a datetime fiel...</td>\n",
       "      <td>['php', 'mysql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to terminate windows phone 8.1 app</td>\n",
       "      <td>['c#']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get current time in a specific country via jquery</td>\n",
       "      <td>['javascript', 'jquery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Configuring Tomcat to Use SSL</td>\n",
       "      <td>['java']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                      tags\n",
       "0                How to draw a stacked dotplot in R?                     ['r']\n",
       "1  mysql select all records where a datetime fiel...          ['php', 'mysql']\n",
       "2             How to terminate windows phone 8.1 app                    ['c#']\n",
       "3  get current time in a specific country via jquery  ['javascript', 'jquery']\n",
       "4                      Configuring Tomcat to Use SSL                  ['java']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('./data/test.tsv', sep='\\t')\n",
    "\n",
    "print('Shape of data')\n",
    "print(f'Train: {train.shape}')\n",
    "print(f'Test: {test.shape}')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function literal_eval in module ast:\n",
      "\n",
      "literal_eval(node_or_string)\n",
      "    Safely evaluate an expression node or a string containing a Python\n",
      "    expression.  The string or node provided may only consist of the following\n",
      "    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,\n",
      "    sets, booleans, and None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tags = train.tags.apply(ast.literal_eval)\n",
    "test.tags = test.tags.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.title.values, train.tags.values\n",
    "X_test, y_test = test.title.values, test.tags.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub('[/(){}\\[\\]\\|@,;]', ' ', text)\n",
    "    text = re.sub('[^0-9a-z #+_]', '', text)\n",
    "    text = ' '.join([word for word in str(text).split()\n",
    "                     if word not in set(stopwords.words('english'))])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:33<00:00, 1074.06it/s]\n",
      "100%|██████████| 30000/30000 [00:27<00:00, 1071.99it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = [clean_text(text) for text in tqdm.tqdm(X_train)]\n",
    "X_test = [clean_text(text) for text in tqdm.tqdm(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['draw stacked dotplot r',\n",
       " 'mysql select records datetime field less specified value',\n",
       " 'terminate windows phone 81 app']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = collections.defaultdict(lambda: 0)\n",
    "for text in X_train:\n",
    "    for word in text.split():\n",
    "        word2count[word] += 1\n",
    "\n",
    "tag2count = collections.defaultdict(lambda: 0)\n",
    "for tags in y_train:\n",
    "    for tag in tags:\n",
    "        tag2count[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('javascript', 19078), ('c#', 19077), ('java', 18661)]\n",
      "[('using', 8278), ('php', 5614), ('java', 5501)]\n"
     ]
    }
   ],
   "source": [
    "most_common_tags = sorted(tag2count.items(),\n",
    "                          key=lambda x: x[1],\n",
    "                          reverse=True)\n",
    "most_common_words = sorted(word2count.items(),\n",
    "                          key=lambda x: x[1],\n",
    "                          reverse=True)\n",
    "print(most_common_tags[:3])\n",
    "print(most_common_words[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (100000, 100)\n",
      "y_test shape: (30000, 100)\n",
      "CPU times: user 136 ms, sys: 76 ms, total: 212 ms\n",
      "Wall time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tag2count.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.fit_transform(y_test)\n",
    "\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 31497\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of words: {len(word2count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "\n",
    "WORD2INDEX = {token[0]: i\n",
    "              for i, token in enumerate(most_common_words[:VOCAB_SIZE])}\n",
    "INDEX2WORD = {v: k for k, v in WORD2INDEX.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow(text, word2index=WORD2INDEX, vocab_size=VOCAB_SIZE):\n",
    "    vect = np.zeros(vocab_size)\n",
    "    for word in text.split():\n",
    "        if word in word2index:\n",
    "            vect[word2index[word]] += 1\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:26<00:00, 3733.64it/s]\n",
      "100%|██████████| 30000/30000 [00:07<00:00, 3817.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_bow shape: (100000, 5000)\n",
      "X_test_bow shape: (30000, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train_bow = sp.sparse.vstack([sp.sparse.csr_matrix(get_bow(text))\n",
    "                                for text in tqdm.tqdm(X_train)])\n",
    "X_test_bow = sp.sparse.vstack([sp.sparse.csr_matrix(get_bow(text))\n",
    "                               for text in tqdm.tqdm(X_test)])\n",
    "\n",
    "print('X_train_bow shape:', X_train_bow.shape)\n",
    "print('X_test_bow shape:', X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf shape: (100000, 18300)\n",
      "X_test_tfidf shape: (30000, 18300)\n",
      "CPU times: user 4.43 s, sys: 48 ms, total: 4.48 s\n",
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer = TfidfVectorizer(token_pattern='\\S+',\n",
    "                                   min_df=5, max_df=0.9,\n",
    "                                   ngram_range=(1, 2))\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print('X_train_tfidf shape:', X_train_tfidf.shape)\n",
    "print('X_test_tfidf shape:', X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf, X_tr, y_tr, params=None):\n",
    "    if params is None:\n",
    "        model = OneVsRestClassifier(estimator=clf)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        return model\n",
    "    else:\n",
    "        params = {f'estimator__{k}': v for k, v in params.items()}\n",
    "        # print(params)\n",
    "        gs = GridSearchCV(OneVsRestClassifier(estimator=clf),\n",
    "                          param_grid=params, cv=10,\n",
    "                          scoring=make_scorer(f1_score,\n",
    "                                              average='weighted'),\n",
    "                          verbose=3, n_jobs=-1)\n",
    "        gs.fit(X_tr, y_tr)\n",
    "        print(f'Best CV score: {gs.best_score_:.5f}')\n",
    "        return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'C': [0.1, 1, 5, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'random_state': [SEED],\n",
    "    'max_iter': [1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_bow = train_model(LogisticRegression(),\n",
    "                      X_tr=X_train_bow,\n",
    "                      y_tr=y_train,\n",
    "                      params=lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf_tfidf = train_model(LogisticRegression(),\n",
    "                        X_tr=X_train_tfidf,\n",
    "                        y_tr=y_train,\n",
    "                        params=lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow = f1_score(y_test, clf_bow.predict(X_test_bow),\n",
    "                      average='weighted')\n",
    "y_pred_tfidf = f1_score(y_test, clf_tfidf.predict(X_test_bow),\n",
    "                        average='weighted')\n",
    "\n",
    "print('LR + BOW - F1 score:', y_pred_bow)\n",
    "print('LR + TF-IDF - F1 score:', y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_important_features(clf, tag, tags_classes,\n",
    "                                  index2word=INDEX2WORD):\n",
    "    print(f'Tag: {tag}')\n",
    "    coef = classifier.coef_[tags_classes.index(tag)]\n",
    "    top_pos_words = [index2word[idx] for idx in coef.argsort()[-1:-6:-1]]\n",
    "    top_neg_words = [index2word[idx] for idx in coef.argsort()[:5]]\n",
    "    print('Top 5 positive words: \\t{}'.format(', '.join(top_pos_words)))\n",
    "    print('Top 5 negative words: \\t{}'.format(', '.join(top_neg_words)))\n",
    "    \n",
    "\n",
    "print_most_important_features(clf_tfidf, 'c',\n",
    "                              mlb.classes, tfidf_reversed_vocab)\n",
    "print_most_important_features(clf_tfidf, 'c++',\n",
    "                              mlb.classes, tfidf_reversed_vocab)\n",
    "print_most_important_features(clf_tfidf, 'linux',\n",
    "                              mlb.classes, tfidf_reversed_vocab)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
