{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "import tqdm\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "SEED = 78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "Train: (100000, 2)\n",
      "Test: (30000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to draw a stacked dotplot in R?</td>\n",
       "      <td>['r']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysql select all records where a datetime fiel...</td>\n",
       "      <td>['php', 'mysql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to terminate windows phone 8.1 app</td>\n",
       "      <td>['c#']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get current time in a specific country via jquery</td>\n",
       "      <td>['javascript', 'jquery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Configuring Tomcat to Use SSL</td>\n",
       "      <td>['java']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                      tags\n",
       "0                How to draw a stacked dotplot in R?                     ['r']\n",
       "1  mysql select all records where a datetime fiel...          ['php', 'mysql']\n",
       "2             How to terminate windows phone 8.1 app                    ['c#']\n",
       "3  get current time in a specific country via jquery  ['javascript', 'jquery']\n",
       "4                      Configuring Tomcat to Use SSL                  ['java']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('./data/test.tsv', sep='\\t')\n",
    "\n",
    "print('Shape of data')\n",
    "print(f'Train: {train.shape}')\n",
    "print(f'Test: {test.shape}')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function literal_eval in module ast:\n",
      "\n",
      "literal_eval(node_or_string)\n",
      "    Safely evaluate an expression node or a string containing a Python\n",
      "    expression.  The string or node provided may only consist of the following\n",
      "    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,\n",
      "    sets, booleans, and None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tags = train.tags.apply(ast.literal_eval)\n",
    "test.tags = test.tags.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.title.values, train.tags.values\n",
    "X_test, y_test = test.title.values, test.tags.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub('[/(){}\\[\\]\\|@,;]', ' ', text)\n",
    "    text = re.sub('[^0-9a-z #+_]', '', text)\n",
    "    text = ' '.join([word for word in str(text).split()\n",
    "                     if word not in set(stopwords.words('english'))])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:35<00:00, 1043.24it/s]\n",
      "100%|██████████| 30000/30000 [00:27<00:00, 1073.10it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = [clean_text(text) for text in tqdm.tqdm(X_train)]\n",
    "X_test = [clean_text(text) for text in tqdm.tqdm(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['draw stacked dotplot r',\n",
       " 'mysql select records datetime field less specified value',\n",
       " 'terminate windows phone 81 app']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = collections.defaultdict(lambda: 0)\n",
    "for text in X_train:\n",
    "    for word in text.split():\n",
    "        word2count[word] += 1\n",
    "\n",
    "tag2count = collections.defaultdict(lambda: 0)\n",
    "for tags in y_train:\n",
    "    for tag in tags:\n",
    "        tag2count[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('javascript', 19078), ('c#', 19077), ('java', 18661)]\n",
      "[('using', 8278), ('php', 5614), ('java', 5501)]\n"
     ]
    }
   ],
   "source": [
    "most_common_tags = sorted(tag2count.items(),\n",
    "                          key=lambda x: x[1],\n",
    "                          reverse=True)\n",
    "most_common_words = sorted(word2count.items(),\n",
    "                          key=lambda x: x[1],\n",
    "                          reverse=True)\n",
    "print(most_common_tags[:3])\n",
    "print(most_common_words[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 132 ms, total: 292 ms\n",
      "Wall time: 293 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tag2count.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.fit_transform(y_test)\n",
    "\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 31498\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of words: {len(word2count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "\n",
    "WORD2INDEX = {token[0]: i\n",
    "              for i, token in enumerate(most_common_words[:VOCAB_SIZE])}\n",
    "INDEX2WORD = {v: k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow(text, word2index=WORD2INDEX, vocab_size=VOCAB_SIZE):\n",
    "    vect = np.zeros(vocab_size)\n",
    "    for word in text.split():\n",
    "        if word in word2index:\n",
    "            vect[word2index[word]] += 1\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:28<00:00, 3536.00it/s]\n",
      "100%|██████████| 30000/30000 [00:08<00:00, 3723.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (100000, 5000)\n",
      "X_test shape: (30000, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train_bow = sp.sparse.vstack([sp.sparse.csr_matrix(get_bow(text))\n",
    "                                for text in tqdm.tqdm(X_train)])\n",
    "X_test_bow = sp.sparse.vstack([sp.sparse.csr_matrix(get_bow(text))\n",
    "                                for text in tqdm.tqdm(X_test)])\n",
    "\n",
    "print('X_train_bow shape:', X_train_bow.shape)\n",
    "print('X_test_bow shape:', X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.44 s, sys: 60 ms, total: 4.5 s\n",
      "Wall time: 4.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer = TfidfVectorizer(token_pattern='\\S+',\n",
    "                                   min_df=5, max_df=0.9,\n",
    "                                   ngram_range=(1, 2))\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print('X_train_tfidf shape:', X_train_tfidf.shape)\n",
    "print('X_test_tfidf shape:', X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
